# ROSSMANN STORE SALES: Previs√£o de Vendas üìä‚úÖ
![img_Rossmann](img/rossman.png)
## Introdu√ß√£o

Este √© um projeto de previs√£o de vendas para as lojas da Rossmann, que segue o m√©todo CRISP-DS (Cross Industry Standard Process for Data Mining). O CRISP-DS √© um processo padr√£o da ind√∫stria para projetos de minera√ß√£o de dados e ci√™ncia de dados, que envolve v√°rias etapas desde a compreens√£o do problema de neg√≥cios at√© a implanta√ß√£o do modelo. Vamos explicar cada etapa at√© agora:

## 1. Quest√£o de Neg√≥cio
Recebemos a demanda de todos os gerentes de lojas da Rossmann para fazer uma previs√£o de vendas dos pr√≥ximos 6 meses para cada uma das lojas. Essa √© a quest√£o de neg√≥cio que estamos tentando resolver.

## 2. Entendimento do Neg√≥cio
Para entender melhor o motivo dessa demanda, conversamos com as partes interessadas e descobrimos que o problema fundamental √© que o CFO da Rossmann precisa estimar o or√ßamento para reformas das lojas, e isso depende diretamente das vendas futuras de cada loja. Portanto, a precis√£o na previs√£o de vendas √© crucial para o planejamento financeiro.

## 3. Coleta de Dados
Na vida real, a coleta de dados envolveria solicita√ß√µes de API, consultas SQL e integra√ß√£o de v√°rias fontes de dados. No entanto, para fins pr√°ticos, optamos por usar os dados dispon√≠veis na plataforma Kaggle como fonte de dados para este projeto.

## 4. Limpeza dos Dados
A limpeza dos dados √© uma etapa cr√≠tica para garantir a qualidade dos dados de entrada no modelo de previs√£o. Dividimos esse processo em tr√™s passos:
### Passo 1: Descri√ß√£o dos Dados
Come√ßamos com uma an√°lise geral dos dados para entender o tamanho do problema.
### Passo 2: Feature Engineering
Realizamos a engenharia de recursos para derivar vari√°veis adicionais que poderiam ser √∫teis em nossa an√°lise, como extrair informa√ß√µes de data e hora.
### Passo 3: Filtragem das Vari√°veis
Filtramos as vari√°veis com base nas restri√ß√µes de neg√≥cios, removendo aquelas que n√£o s√£o relevantes para a previs√£o de vendas.

## 5. Explora√ß√£o dos Dados
Nesta etapa, realizamos an√°lises univariadas, bivariadas e multivariadas para descobrir correla√ß√µes, validar hip√≥teses e gerar insights sobre os dados. Isso nos ajuda a entender melhor o comportamento das vari√°veis e sua rela√ß√£o com as vendas.

## 6. Modelagem dos Dados
A modelagem dos dados √© uma fase cr√≠tica onde constru√≠mos o modelo de previs√£o. Ela se divide em dois passos:
### Passo 1: Prepara√ß√£o dos Dados
Neste passo, aplicamos t√©cnicas de pr√©-processamento, como rescaling, encoding e transforma√ß√µes, para deixar os dados o mais pr√≥ximo poss√≠vel de uma distribui√ß√£o normal e para transformar vari√°veis categ√≥ricas em num√©ricas.
### Passo 2: Filtragem das Vari√°veis Mais Relevantes
Aqui, removemos vari√°veis colineares, ou seja, vari√°veis que explicam a mesma parte do fen√¥meno, para evitar multicolinearidade e melhorar a interpretabilidade do modelo. O metodo utilizado para fazer a sele√ß√£o das vari√°veis mais importantes para o modelo foi **Boruta**. O m√©todo Boruta √© √∫til para evitar overfitting, garantindo que apenas as vari√°veis verdadeiramente informativas sejam mantidas no modelo, contribuindo para um melhor desempenho de aprendizado de m√°quina e interpretabilidade dos resultados.

Aqui est√° uma breve vis√£o geral:

1. **Cria√ß√£o de Caracter√≠sticas Sombra**: O m√©todo cria uma c√≥pia das vari√°veis de entrada, chamada de "caracter√≠sticas sombra".

2. **Conjunto de Dados Expandido**: As vari√°veis originais e as caracter√≠sticas sombra s√£o combinadas em um √∫nico conjunto de dados expandido.

3. **Aprendizado de M√°quina**: Aplica-se um algoritmo de aprendizado de m√°quina, como uma floresta aleat√≥ria, ao conjunto de dados expandido para avaliar a import√¢ncia de cada vari√°vel.

4. **Sele√ß√£o Iterativa**: As vari√°veis originais que consistentemente superam as caracter√≠sticas sombra em import√¢ncia estat√≠stica s√£o selecionadas como relevantes.

5. **Evita Overfitting**: Esse m√©todo ajuda a evitar o overfitting, garantindo que apenas as vari√°veis verdadeiramente informativas sejam mantidas no modelo, resultando em um melhor desempenho e interpretabilidade.

Agora, estamos prontos para avan√ßar para as etapas seguintes do CRISP-DS, que envolvem a sele√ß√£o de algoritmos de machine learning, avalia√ß√£o do desempenho do modelo e, se necess√°rio, repeti√ß√£o do ciclo para ajustar o modelo at√© que ele atenda √†s expectativas de acur√°cia. 